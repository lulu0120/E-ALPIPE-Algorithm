For benchmark selection
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(MASS)
library(stats)
library(purrr)
library(truncnorm)
library(posterior)
library(deSolve)
library(bayestestR)
library(coda)

noise_1= 0.005

theta_A = c(0,3)
theta_B = c(3,6)

param_matrix=matrix(c(theta_A[1],theta_B[1],theta_A[2],theta_B[2]),nrow=1,byrow=FALSE)
```
Define function
```{r}
 
original_function = function(T_2, theta1, theta2) {
  x3 = exp(-theta1 * T_2) + exp(-theta2 * T_2)
  return(x3) #report the value at T2
}

 
original_function_vec = function(T_2_vec, theta1, theta2) {
  t_sorted = sort(T_2_vec)
  x3 = exp(-theta1 * t_sorted) + exp(-theta2 * t_sorted)
  out = data.frame(time = t_sorted, x3 = x3)
  return(out)
}
 
similar_function = function(info, time_length = 10) {
  n_samples = nrow(info)
  unique_T2 = seq(1, time_length, 0.1)
  n_T2 = length(unique_T2)

  x3_mat = matrix(NA_real_, nrow = n_samples, ncol = n_T2)
  for (i in seq_len(n_samples)) {
    theta1 = info$theta1[i]
    theta2 = info$theta2[i]
    x3_vals = exp(-theta1 * unique_T2) + exp(-theta2 * unique_T2)
    x3_mat[i, ] = x3_vals
  }

  x3_df = as.data.frame(x3_mat)
  #colnames(x3_df) = paste0("T2_", unique_T2)
  return(x3_df)
}

# Update repeated sampling dictionary
update_repeat_dict = function(contain_index_pairs, existing_dict) {
  if (is.null(existing_dict)) {
    existing_dict = list()
  }
  for (pair in contain_index_pairs) {
    key = paste(pair, collapse = "_")
    if (!is.null(existing_dict[[key]])) {
      existing_dict[[key]] = existing_dict[[key]] + 1
    } else {
      existing_dict[[key]] = 1
    }
  }
  return(existing_dict) 
}

#Generate noisy observation
generate_obs = function(T2_values, seed, repeated_dict, noise = noise_1) {
  key = paste(T2_values, collapse = "_")
  repeated_times = repeated_dict[[key]]
  if (is.null(repeated_times)) stop("Counting error, key does not exist.")
  seed = 30 * seed + sum(unlist(repeated_dict))
  set.seed(seed)

  obs_clean = original_function(T2_values, theta1 = 2, theta2 = 4)
  obs_noisy = obs_clean + rtruncnorm(1, a = -obs_clean, b = Inf, mean = 0, sd = noise)
  return(list(obs_noisy))
}


 

 
calculate_truncated_variance = function(mu_list, sigma, lower_limit = 0) {
  variances = numeric(length(mu_list))
  for (i in seq_along(mu_list)) {
    mu = mu_list[i]
    alpha = (lower_limit - mu) / sigma
    phi_alpha = dnorm(alpha)
    Phi_alpha = pnorm(alpha)
    variance = sigma^2 * (1 - ((alpha * phi_alpha) / (1 - Phi_alpha)) - (phi_alpha / (1 - Phi_alpha))^2)
    variances[i] = variance
  }
  return(variances)
}

 
similar_function_single = function(info, times = seq(1, 10, 0.1)) {
  theta1 = info[1]
  theta2 = info[2]
  x3_vals = exp(-theta1 * times) + exp(-theta2 * times)
  return(list(y1 = x3_vals))
}
```

Search for MLE  
```{r}
negative_log_likelihood_profile = function(parameters, obs1, T_2, noise_1, fixed_param = NULL, param_index = NULL) {

  if (!is.null(fixed_param) && !is.null(param_index)) {
    full_params = numeric(2)
    full_params[param_index] = fixed_param
    full_params[-param_index] = parameters
  } else {
    full_params = parameters
  }

  # Sanity checks
  if (any(!is.finite(full_params)) || any(!is.finite(obs1)) || any(!is.finite(T_2))) return(1e60)
  if (!is.finite(noise_1) || noise_1 <= 0) return(1e60)

  theta1 = full_params[1]
  theta2 = full_params[2]

  likelihood = tryCatch(
    dtruncnorm(obs1, a = 0, b = Inf, mean = exp(-theta1 * T_2) + exp(-theta2 * T_2), sd = noise_1),
    error = function(e) rep(1e-10, length(obs1))
  )

  likelihood[!is.finite(likelihood) | likelihood <= 0] = 1e-10

  nll = -sum(log(likelihood))
  if (!is.finite(nll)) return(1e60)
  verbose = TRUE
  if (verbose) {
  #cat("theta1 =", theta1, "theta2 =", theta2, "\n")
  #cat("pred_x3 =", round(pred_x3, 5), "\n")
  #cat("obs1 =", round(obs1, 5), "\n")
  #cat("nll =", nll, "\n\n")
}
  return(nll)
  
}
```

Discretisation
```{r}
single_pid=function(LBs,UBs){
  check_vector = ifelse(is.na(LBs) | is.na(UBs), 0, 1)
  return(check_vector)
}

common_optim_settings = list(
  method = "L-BFGS-B",
  noise_1 = noise_1,
  control = list(maxit = 1000)  # Maximum iterations
)


compute_profile_likelihood <- function(fix_param_value, init_params, fix_idx) {
  settings = list(
    par = init_params,
    fn  = negative_log_likelihood_profile,
    obs1 = y_1,
    T_2  = T_2,
    noise_1 = noise_1,
    fixed_param = fix_param_value,
    param_index = fix_idx,
    lower = params_matrix[1, 1:2][-fix_idx],
    upper = params_matrix[1, 3:4][-fix_idx]
  )
  
  pl = do.call(optim, modifyList(common_optim_settings, settings))
  
  neglog_lik = pl$value
  optimized_free = pl$par
  
  optimized_params = numeric(2)
  optimized_params[-fix_idx] = optimized_free
  optimized_params[ fix_idx] = fix_param_value
  
  return(list(neglog_lik = neglog_lik, optimized_params = optimized_params))
}

 

id_check_together = function(f, MLE, tol, initial_param, LB, UB, threshold, fix_idx, prev_bound = NULL, n_grid = 2) {
  grid_vals = seq(LB, UB, length.out = n_grid)
  pl_vals = sapply(grid_vals, function(v) f(v, initial_param, fix_idx)$neglog_lik)

  cat("\n", paste(pl_vals, collapse = " | "), "\n")

  left_idx  = grid_vals <= MLE
  right_idx = grid_vals >  MLE
  left_pl   = pl_vals[left_idx]
  right_pl  = pl_vals[right_idx]

  if (any(left_pl > threshold) && any(right_pl > threshold)) {
    return(check_result = 1)
  } else {
    cat("Not identifiable for parameter", fix_idx, "\n")
    return(check_result = 0)
  }
}

bound_search_ci = function(f, MLE, tol, initial_param, LB, UB, id_indicator, threshold, fix_idx, prev_bound = NULL, max_iter = 50) {
  length_int = 10
  interval_split = seq(from = LB, to = UB, length.out = length_int)
  pl_models = data.frame()
  
  min_pt = numeric(length(initial_param) + 1)
  min_pt[-fix_idx] = initial_param
  min_pt[fix_idx]  = MLE
  min_pl = threshold - qchisq(0.95, 1) / 2

  if (id_indicator[fix_idx] == 0) {
    cat("The id check for ", fix_idx, "is", id_indicator[fix_idx], "\n")
    pl_values = numeric(length(interval_split))
    for (i in seq_along(interval_split)) {
      pl_model = f(interval_split[i], initial_param, fix_idx)
      param_row = as.data.frame(t(pl_model$optimized_params))
      pl_models = rbind(pl_models, param_row)
      pl_values[i] = pl_model$neglog_lik
    }
    return(list(closest_lower = NA, closest_upper = NA,
                iterations_lower = NA, iterations_upper = NA,
                pl_models = pl_models, best_pl = min_pl, update_MLE = min_pt))
  }

  # Lower bound search
  search_points = data.frame(point = numeric(0), value = numeric(0), region = character(0))
  lower = LB
  upper = MLE
  iter = 0
  while (abs(upper - lower) > tol && iter < max_iter) {
    mid = (lower + upper) / 2
    pl_mid = f(mid, initial_param, fix_idx)$neglog_lik
    search_points = rbind(search_points, data.frame(point = mid, value = pl_mid, region = "lower"))

    if (abs(pl_mid - threshold) < min_pl) {
      min_pl = abs(pl_mid - threshold)
      min_pt[fix_idx] = mid
    }
    if (pl_mid < threshold) {
      upper = mid
    } else {
      lower = mid
    }
    iter = iter + 1
  }
  closest_lower = if (iter == 0) (LB + MLE) / 2 else mid
  iter_lower = iter

  # Upper bound search
  lower = MLE
  upper = UB
  iter = 0
  while (abs(upper - lower) > tol && iter < max_iter) {
    mid = (lower + upper) / 2
    pl_mid = f(mid, initial_param, fix_idx)$neglog_lik
    search_points = rbind(search_points, data.frame(point = mid, value = pl_mid, region = "upper"))

    if (abs(pl_mid - threshold) < min_pl) {
      min_pl = abs(pl_mid - threshold)
      min_pt[fix_idx] = mid
    }
    if (pl_mid < threshold) {
      lower = mid
    } else {
      upper = mid
    }
    iter = iter + 1
  }
  closest_upper = if (iter == 0) (UB + MLE) / 2 else mid
  iter_upper = iter

  # Evaluate inner points
  selected = interval_split[interval_split > closest_lower & interval_split < closest_upper]
  if (length(selected) == 0) selected = (closest_lower + closest_upper) / 2

  pl_values = numeric(length(selected))
  for (i in seq_along(selected)) {
    pl_model = f(selected[i], initial_param, fix_idx)
    param_row = as.data.frame(t(pl_model$optimized_params))
    pl_models = rbind(pl_models, param_row)
    pl_values[i] = pl_model$neglog_lik
  }

  cat("Length of selected", length(selected), 
      "Width of the interval", closest_upper - closest_lower, "\n")

  return(list(
    closest_lower = closest_lower,
    closest_upper = closest_upper,
    iterations_lower = iter_lower,
    iterations_upper = iter_upper,
    pl_models = pl_models,
    update_MLE = min_pt,
    best_pl = min_pl
  ))
}
```

Joint work: update_functions (identifiability) 
```{r}
update_functions_id  = function(y_1, T_2, num_points, 
                                   prev_MLE = c(1, 5),   #maybe change to some other values
                                   prev_opt = NULL,
                                   prev_bound = NULL,
                                   params_matrix = param_matrix) {
  
  params_matrix <<- params_matrix
  y_1 <<- y_1
  T_2 <<- T_2
  
  unique_T2 = seq(1, num_points, 0.1)
  lowerbound = params_matrix[1, 1:2]
  upperbound = params_matrix[1, 3:4]
  colnames(params_matrix) = c("theta1_L", "theta2_L", "theta1_U", "theta2_U")

  # 3 random starting points for optimization
  starts = list(prev_MLE,c(1, 4), c(2, 5))

  one_run = function(p0) {
    optim(
      par = p0,
      fn = negative_log_likelihood_profile,
      obs1 = y_1,
      T_2 = T_2,
      noise_1 = noise_1,
      method = "L-BFGS-B",
      lower = params_matrix[1, 1:2],
      upper = params_matrix[1, 3:4],
      control = list(
        maxit = 5000
      )
    )
  }

  res_list = lapply(starts, one_run)
  best_idx = which.min(sapply(res_list, `[[`, "value"))

  purrr::imap(res_list, function(res, idx) {
    cat("Start", idx, "→ value =", res$value,
        "  par =", paste(round(res$par, 6), collapse = ", "), "\n")
  })

  optim_results_mle = res_list[[best_idx]]
  mle_params = optim_results_mle$par
  cat("MLEs:", paste(mle_params, collapse = " | "), "\n")

  # Previous likelihood for comparison
  prev_pl = if (!is.null(prev_opt)) {
    negative_log_likelihood_profile(prev_opt, y_1, T_2, noise_1)
  } else {
    1e6
  }

  current_pl = negative_log_likelihood_profile(mle_params, y_1, T_2, noise_1)
  mle_params = if (current_pl < prev_pl) mle_params else prev_MLE
  MLE_neglog = min(current_pl, prev_pl)

  # Identifiability check
  min_stepsize = c(0.05, 0.05)
  threshold = current_pl + qchisq(0.95, 1) / 2
  param_indices = 1:2

  id_check = sapply(param_indices, function(i) {
    id_check_together(
      f = compute_profile_likelihood,
      MLE = mle_params[i],
      tol = min_stepsize[i],
      initial_param = mle_params[-i],
      LB = lowerbound[[i]],
      UB = upperbound[[i]],
      threshold = threshold,
      prev_bound = if (!is.null(prev_bound)) as.numeric(prev_bound[i, 1:2]) else NULL,
      fix_idx = i
    )
  })

  cat("idcheckresult", id_check, "\n")

  # Bound search
  bounds = lapply(param_indices, function(i) {
    bound_search_ci(
      f = compute_profile_likelihood,
      MLE = mle_params[i],
      tol = min_stepsize[i],
      initial_param = mle_params[-i],
      LB = lowerbound[[i]],
      UB = upperbound[[i]],
      id_indicator = id_check,
      threshold = threshold,
      prev_bound = if (!is.null(prev_bound)) as.numeric(prev_bound[i, 1:2]) else NULL,
      fix_idx = i,
      max_iter = 50
    )
  })

  bounds_df = do.call(rbind, lapply(bounds, function(x) as.data.frame(x[1:4])))
  best_pl_values = sapply(bounds, function(x) x$best_pl)
  min_best_pl_index = which.min(best_pl_values)
  update_MLE = bounds[[min_best_pl_index]]$update_MLE

  all_pl_models_df = do.call(rbind, lapply(bounds, function(x) x$pl_models))
  cat("The number of rows:", nrow(all_pl_models_df), "\n")

  colnames(all_pl_models_df) <- c("theta1", "theta2")

  # Compute output function values
  functions_df = similar_function(all_pl_models_df, time_length = num_points)
  determinant = numeric(ncol(functions_df))

  for (i in seq_along(determinant)) {
    data_col = as.numeric(functions_df[, i])
    determinant[i] = var(data_col)
  }

  max_var_idx = which.max(determinant)
  selected_T2 = unique_T2[max_var_idx]

  cat("Id check for iter", length(T_2), "→", paste(id_check, collapse = " "), "\n")
  return(list(selected_T2, mle_params, id_check, current_model = NULL, bounds_df))
}
```

Joint work: each trial
```{r}
iteration_func = function(seed, candidate_T2, iterations, num_points, noise_1 = noise_1) {
  cat("trial: ", seed, "\n")
  set.seed(seed)

  estimate_df = list()
  pid_df = list()
  bounds_df = list()

  N = 1
  selected_T2 = c(3, sample(candidate_T2, N - 1, replace = TRUE))
  cat("Initial T2:", selected_T2, "\n")

  contain_pairs = lapply(selected_T2, function(x) c(x))
  repeat_count = update_repeat_dict(contain_pairs, list())

  obs1 = numeric(0)
  for (idx in seq_along(contain_pairs)) {
    obs_generated = generate_obs(contain_pairs[[idx]], seed, repeat_count)
    obs1 = c(obs1, as.numeric(obs_generated[1]))
  }

  y_1 = obs1
  cat("Initial y_1:", y_1, "\n")

  result_iter = update_functions_id(
    y_1 = y_1[order(unlist(contain_pairs))],
    T_2 = sort(unlist(contain_pairs)),
    num_points = num_points
  )

  next_location = result_iter[[1]]
  current_mle   = result_iter[[2]]
  id_check      = result_iter[[3]]
  current_bound = result_iter[[5]]

  estimate_df[[1]] = current_mle
  observations_df = data.frame(iteration = integer(), y1 = list())

  i = 0
  id_label = 0

  while (i < iterations) {
    i = i + 1
    N = N + 1

    contain_pairs = c(contain_pairs, list(next_location))
    repeat_count = update_repeat_dict(next_location, repeat_count)

    obs1 = c(obs1, generate_obs(next_location, seed, repeat_count)[[1]])
    y_1 = obs1

    cat("Iteration", i, "T2:", unlist(contain_pairs), "\n")

    current_estimate = c(10, 10)
    current_estimate[id_check == 1] = current_mle[id_check == 1]

    if (id_label < 2) {
      result_iter = update_functions_id(
        y_1 = y_1[order(unlist(contain_pairs))],
        T_2 = sort(unlist(contain_pairs)),
        num_points = num_points,
        prev_MLE = current_estimate,
        prev_opt = current_mle,
        prev_bound = current_bound
      )

      next_location = result_iter[[1]]
      current_mle   = result_iter[[2]]
      id_check      = result_iter[[3]]
      current_bound = result_iter[[5]]
    }

    #if idlabel = 2, stop call function
    #if(sum(id_check)==3){
    #  id_label = id_label+1
    #}
    #else{
    #   id_label = 0
    #}
    #if no early stop
    id_label = 0
    estimate_df[[i]] = current_mle
    pid_df[[i]] = id_check
    observations_df = rbind(observations_df, data.frame(iteration = i, y1 = I(list(y_1))))
    bounds_df[[i]] = result_iter[[5]]
  }

  cat("Final T2 sequence used:", unlist(contain_pairs), "\n")
  return(list(estimate_df, pid_df, observations_df, contain_pairs, bounds_df))
}
```

Trial function:
```{r}

trials = function(num_trials, iterations, time_length,noise_1=noise_1){
  trialseq = seq(1, num_trials)
  T_2= seq(1, time_length, 0.1) 
  estimated_params=list()
  observations=list()
  pl_check=list()
  bounds=list()
  obs_locations_df = data.frame(matrix(ncol = length(iterations+1), nrow = 0))
  for (i in 1:length(trialseq)) {
    cat("Start trial",i,"\n","\n","\n")
 
    results=iteration_func(trialseq[i],T_2,iterations,time_length)
    estimated_params[[i]]=results[1]
    pl_check[[i]]=results[2]
    observations[[i]]= results[3] #results 4 is dataframe, so a list of dataframe structure
    row_df = as.data.frame(t(unlist(results[[4]])))
    obs_locations_df=rbind(obs_locations_df, row_df)
    bounds[[i]]=results[5]
  }
  milly = list(estimated_params,observations,obs_locations_df,pl_check,bounds)
  save(milly, file = "1DbenchmarkEXP.RData") 
  return(list(estimated_params,observations,obs_locations_df,pl_check,bounds)) 
}
 
```

